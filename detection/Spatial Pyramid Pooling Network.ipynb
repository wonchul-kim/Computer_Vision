{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주요 기여:  입력 이미지 크기와 상관없이 CNN을 적용할 수 있도록 하는 Spatial Pyramid Pooling 기법을 제안하였습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 핵심 아이디어\n",
    "기존의 CNN 아키텍쳐들은 모두 입력 이미지가 고정되어야 했습니다. (ex. 224 x 224) 그렇기 때문에 신경망을 통과시키기 위해서는 이미지를 고정된 크기로 크롭하거나 비율을 조정(warp)해야 했습니다. 하지만 이렇게 되면 물체의 일부분이 잘리거나, 본래의 생김새와 달라지는 문제점이 있습니다. 여기서 저자들의 아이디어가 시작합니다.\n",
    "\n",
    "\"입력 이미지의 크기나 비율에 관계 없이 CNN을 학습 시킬 수는 없을까?\"\n",
    "<img src='./imgs/spp1.png'>\n",
    "\n",
    "Convolution 필터들은 사실 입력 이미지가 고정될 필요가 없습니다. sliding window 방식으로 작동하기 때문에, 입력 이미지의 크기나 비율에 관계 없이 작동합니다. 입력 이미지 크기의 고정이 필요한 이유는 바로 컨볼루션 레이어들 다음에 이어지는 fully connected layer가 고정된 크기의 입력을 받기 때문입니다. 여기서 Spatial Pyramid Pooling(이하 SPP)이 제안됩니다.\n",
    "\n",
    "\"입력 이미지의 크기에 관계 없이 Conv layer들을 통과시키고,\n",
    "\n",
    "FC layer 통과 전에 피쳐 맵들을 동일한 크기로 조절해주는 pooling을 적용하자!\"\n",
    " \n",
    "\n",
    "입력 이미지의 크기를 조절하지 않은 채로 컨볼루션을 진행하면 원본 이미지의 특징을 고스란히 간직한 피쳐 맵을 얻을 수 있습니다. 또한 사물의 크기 변화에 더 견고한 모델을 얻을 수 있다는 것이 저자들의 주장입니다. 또한 이는 Image Classification이나 Object Detection과 같은 여러 테스크들에 일반적으로 적용할 수 있다는 장점이 있습니다.\n",
    "\n",
    " \n",
    "### 2. overview\n",
    "\n",
    "1. 먼저 전체 이미지를 미리 학습된 CNN을 통과시켜 피쳐맵을 추출합니다.\n",
    "\n",
    "2. Selective Search를 통해서 찾은 각각의 RoI들은 제 각기 크기와 비율이 다릅니다. 이에 SPP를 적용하여 고정된 크기의 feature vector를 추출합니다.\n",
    "\n",
    "3. 그 다음 fully connected layer들을 통과 시킵니다.\n",
    "\n",
    "4. 앞서 추출한 벡터로 각 이미지 클래스 별로 binary SVM Classifier를 학습시킵니다.\n",
    "\n",
    "5. 마찬가지로 앞서 추출한 벡터로 bounding box regressor를 학습시킵니다. \n",
    "\n",
    "본 논문의 가장 핵심은 Spatial Pyramid Pooling을 통해서 각기 크기가 다른 CNN 피쳐맵 인풋으로부터 고정된 크기의 feature vector를 뽑아내는 것에 있습니다. 그 이후의 접근 방식은 R-CNN과 거의 동일합니다. 그렇다면 SPP에 대해서 좀 더 자세히 알아보고, Object Detection에서는 어떻게 적용되는 지 알아보겠습니다.\n",
    "\n",
    " \n",
    "### 3. Spatial Pyramid Pooling\n",
    "<img src='./imgs/spp2.png'>\n",
    "\n",
    "먼저 Conv Layer들을 거쳐거 추출된 피쳐맵을 인풋으로 받습니다. 그리고 이를 미리 정해져 있는 영역으로 나누어 줍니다. 위의 예시에서는 미리 4x4, 2x2, 1x1 세 가지 영역을 제공하며, 각각을 하나의 피라미드라고 부릅니다. 즉, 해당 예시에서는 3개의 피라미드를 설정한 것입니다. 피라미드의 한 칸을 bin 이라고 합니다. 예를 들어 입력이 64 x 64 x 256 크기의 피쳐 맵이 들어온다고 했을 때, 4x4의 피라미드의 bin의 크기는 16x16이 됩니다.\n",
    "\n",
    "이제 각 bin에서 가장 큰 값만 추출하는 max pooling을 수행하고, 그 결과를 쭉 이어붙여 줍니다. 입력 피쳐맵의 체널 크기를 k, bin의 개수를 M이라고 했을 때 SPP의 최종 아웃풋은 kM 차원의 벡터입니다. 위의 예시에서 k = 256, M = (16 + 4 + 1) = 21 이 됩니다. 정리해보면 입력 이미지의 크기와는 상관없이 미리 설정한 bin의 개수와 CNN 체널 값으로 SPP의 출력이 결정되므로, 항상 동일한 크기의 결과를 리턴한다고 볼 수 있습니다. 실제 실험에서 저자들은 1x1, 2x2, 3x3, 6x6 총 4개의 피라미드로 SPP를 적용합니다.\n",
    "\n",
    "\n",
    "### 4. Object Detection에의 적용\n",
    "<img src='./imgs/spp3.png'>\n",
    "\n",
    "Object Detection에 SPP를 적용할 수 있습니다. 먼저 저자들은 R-CNN의 문제점을 지적하며 SPP를 이용한 더 효율적인 object detection을 제안합니다. R-CNN은 Selective Search로 찾은 2천개의 물체 영역을 모두 고정 크기로 조절한 다음, 미리 학습된 CNN 모델을 통과시켜 feature를 추출합니다. 때문에 속도가 느릴 수 밖에 없습니다. 반면 SPPNet은 입력 이미지를 그대로 CNN에 통과시켜 피쳐 맵을 추출한 다음, 그 feature map에서 2천개의 물체 영역을 찾아 SPP를 적용하여 고정된 크기의 feature를 얻어냅니다. 그리고 이를 FC와 SVM Classifier에 통과시킵니다.\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "### 5. 한계점\n",
    "SPPNet은 기존 R-CNN이 모든 RoI에 대해서 CNN inference를 한다는 문제점을 획기적으로 개선하였지만 여전히 한계점이 있습니다.\n",
    "\n",
    "1. end-to-end 방식이 아니라 학습에 여러 단계가 필요하다. (fine-tuning, SVM training, Bounding Box Regression)\n",
    "\n",
    "2. 여전히 최종 클래시피케이션은 binary SVM, Region Proposal은 Selective Search를 이용한다.\n",
    "\n",
    "3. fine tuning 시에 SPP를 거치기 이전의 Conv 레이어들을 학습 시키지 못한다. 단지 그 뒤에 Fully Connnected Layer만 학습시킨다.\n",
    "    - 그리고 3번 단점의 경우 형준킴님께서 언급하셨듯이 구현의 편의성때문에 안 한거지 conv layer까지 back prop시키는게 가능은 하지 않나요? 저자가 텐서플로우를 썼었다면... ㅋㅋㅋ\n",
    "    - 논문에는 명확하게 이 부분을 왜 학습 안시켰는지 명시되어있지 않습니다. 다만 이 후 논문인 fast rcnn에서 sppnet의 이러한 한계점을 지적하고, 자신의 차별점으로 conv 레이어까지 학습시키는 것을 들 수 있습니다. 덧붙이자면 해당 논문이 등장한 시기에는 아직 텐서플로우보다는 카페같은 프레임워크를 사용하여 구현하는 경우가 많았습니다. 원문을 보시면 spp pooling을 구현하는데 당대 gpu 프로그래밍 구현상의 한계가 있었다는 언급으로 미루어봐서 기술적 한계가 있었나 봅니다.\n",
    "\n",
    "### Reference\n",
    "[1] He et al, Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition, 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
