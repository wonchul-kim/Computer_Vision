{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./imgs/crossentropy.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tasks\n",
    "우선, 두가지 문제를 봅시다.\n",
    "\n",
    "<img src='./imgs/crossentropy1.png' width=600>\n",
    "\n",
    "#### 1-1. Multi-Class Classfication\n",
    "각 샘플(이미지)은 클래스 C 중 하나로 분류될 수 있습니다.\n",
    "\n",
    "해는 0번, 즉 [1 0 0] (원핫인코딩),\n",
    "\n",
    "달은 1번, [0 1 0],\n",
    "\n",
    "구름은 2번, [0 0 1]\n",
    "\n",
    "으로 분류될 수 있다는 말입니다.\n",
    "\n",
    "CNN은 s(scores) 벡터를 출력하고, one hot 벡터인 타겟(ground truth) 벡터 t와 매칭이 되어 loss값을 계산할 것입니다.\n",
    "\n",
    "즉, Multi-Class Classification은 여러 샘플(이미지)에서 C개의 클래스 중 하나의 클래스로 분류하는 문제로 생각할 수 있습니다.\n",
    "\n",
    "#### 1-2. Multi-Label Classficiation\n",
    "각 샘플은 여러 개의 클래스 객체(object)를 가질 수 있습니다.\n",
    "\n",
    "타겟 벡터 t는 하나 이상의 positive클래스를 가질 수 있고 [1 0 1] 처럼 인코딩 될 수 있습니다.\n",
    "\n",
    "즉, Multi-label Classification은 여러 샘플(이미지)에서 각 샘플 마다 있는 클래스 들을 여러 클래스로 레이블하는 문제입니다.\n",
    "\n",
    "그럼 Multi-Class와 Multi-label 분류에 사용되는 활성화 함수(activation function)와 손실함수(loss function)를 알아보겠습니다.\n",
    "\n",
    "\n",
    "### 2. Activation Function\n",
    "**1) Sigmoid**\n",
    "CNN 마지막 층에서 나온 값을 (0, 1) 사이 값으로 압축하여 줍니다.\n",
    "\n",
    "각 요소 $s_i$에서 각각 적용될 수 있습니다. logistic function이라고 불리기도 합니다.\n",
    "\n",
    "<img src='./imgs/crossentropy2.png' width=300>\n",
    "\n",
    "\n",
    "**2) Softmax**\n",
    "클래스의 스코어를 나타내는 벡터 각각의 요소는 (0, 1) 범위가 되며, 모든 합이 1이 되도록 만들어줍니다.\n",
    "\n",
    "$s_j$는 각 스코어 이고 모든 $i$에 대한 소프트맥스값을 더하면 1이 나옵니다.\n",
    "\n",
    "<img src='./imgs/crossentropy3.png' width=200>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Loss\n",
    "**1) Cross-Entropy Loss**\n",
    "<img src='./imgs/crossentropy4.png'>\n",
    "\n",
    "$t_i$ 는 ground truth (정답), $s_i$는 각 클래스 i에 대한 CNN 마지막 층의 아웃풋인 score 벡터의 $i$번째 요소입니다.\n",
    "\n",
    "(0, 1) 사이 계산 범위를 맞추기 위하여 스코어는 위에서 설명한 sigmoid activation function과 종종 같이 붙어서 CE loss와 계산됩니다.\n",
    "\n",
    "특별히 binary classfication 문제에서는 (즉, C' = 2), 식을 전개해보면 다음과 같이 나옴을 알 수 있습니다.\n",
    "\n",
    "<img src='./imgs/crossentropy5.png'>\n",
    "\n",
    "\n",
    "\n",
    "**2) Categorical Cross-Entropy Loss**\n",
    "Softmax activation 뒤에 Cross-Entropy loss를 붙인 형태로 주로 사용하기 때문에 Softmax loss 라고도 불립니다.\n",
    "\n",
    "→ Multi-class classification에 사용됩니다.\n",
    "\n",
    "우리가 분류문제에서 주로 사용하는 활성화함수와 로스입니다. 분류 문제에서는 MSE(mean square error) loss 보다 CE loss가 더 빨리 수렴한 다는 사실이 알려져있습니다. 따라서 multi class에서 하나의 클래스를 구분할 때 softmax와 CE loss의 조합을 많이 사용합니다.\n",
    "\n",
    "<img src='./imgs/crossentropy6.png'>\n",
    "\n",
    " \n",
    "널리 쓰이는 프레임워크 3가지에서는 multi-class에서 쓸 수 있는 cross entropy loss를 정의해놓았습니다.\n",
    "물론 이는 binary class에서도 적용이 가능합니다. 클래스가 2개일 때 sigmoid와 softmax는 같은 식이 됩니다.\n",
    "\n",
    "* Caffe: SoftmaxWithLoss Layer\n",
    "* Pytorch: torch.nn.CrossEntropyLoss\n",
    "* TensorFlow: tf.nn.softmax_cross_entropy (deprecated) → tf.nn.softmax_cross_entropy_v2\n",
    " \n",
    "**3) Binary Cross-Entropy Loss**\n",
    "Sigmoid activation 뒤에 Cross-Entropy loss를 붙인 형태로 주로 사용하기 때문에 Sigmoid CE loss라고도 불립니다.\n",
    "\n",
    "→ Multi-label classification에 사용됩니다.\n",
    "\n",
    "<img src='./imgs/crossentropy7.png'>\n",
    "\n",
    "<img src='./imgs/crossentropy8.png'>\n",
    " \n",
    "\n",
    "* Caffe: Sigmoid Cross-Entropy Loss Layer\n",
    "* Pytorch: torch.nn.BCEWithLogitsLoss\n",
    "* TensorFlow: tf.nn.sigmoid_cross_entropy_with_logits\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Focal loss\n",
    "Focal loss는 페이스북의 Lin et al. 이 소개했습니다. --> 논문참고 [https://arxiv.org/abs/1708.02002\\]\n",
    "\n",
    "RetinaNet 모델을 학습시키는데 Focal loss가 한단계 객체 탐색기를 향상시킵니다.\n",
    "\n",
    "Focal loss는 분류 에러에 근거한 loss에 가중치를 부여하는데,\n",
    "\n",
    "샘플이 CNN에 의해 이미 올바르게 분류되었다면 그것에 대한 가중치는 감소합니다.\n",
    "\n",
    "즉, 좀 더 문제가 있는 loss에 더 집중하는 방식으로 불균형한 클래스 문제를 해결하였습니다.\n",
    "\n",
    "<img src='./imgs/crossentropy9.png'>\n",
    "\n",
    "<img src='./imgs/crossentropy10.png'>\n",
    "\n",
    " \n",
    "\n",
    "Focal loss는 Sigmoid activation을 사용하기 때문에, Binary Cross-Entropy loss라고도 할 수 있습니다.\n",
    "\n",
    "특별히, r = 0 일때 Focal loss는 Binary Cross Entropy Loss와 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/wonchul/.virtualenvs/p3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Compatible with tensorflow backend\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n",
    "                        - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-eb9843cb27f9>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-eb9843cb27f9>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    super(FocalLoss, self).init()\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "  def init(self, gamma=0, alpha=None, size_average=True):\n",
    "  super(FocalLoss, self).init()\n",
    "  self.gamma = gamma\n",
    "  self.alpha = alpha\n",
    "  if isinstance(alpha,(float,int,long)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "  if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "  self.size_average = size_average\n",
    "\n",
    "  def forward(self, input, target):\n",
    "      if input.dim()>2:\n",
    "          input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "          input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "          input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "      target = target.view(-1,1)\n",
    "\n",
    "      logpt = F.log_softmax(input)\n",
    "      logpt = logpt.gather(1,target)\n",
    "      logpt = logpt.view(-1)\n",
    "      pt = Variable(logpt.data.exp())\n",
    "\n",
    "      if self.alpha is not None:\n",
    "          if self.alpha.type()!=input.data.type():\n",
    "              self.alpha = self.alpha.type_as(input.data)\n",
    "          at = self.alpha.gather(0,target.data.view(-1))\n",
    "          logpt = logpt * Variable(at)\n",
    "\n",
    "      loss = -1 * (1-pt)**self.gamma * logpt\n",
    "      if self.size_average: return loss.mean()\n",
    "      else: return loss.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처: https://gombru.github.io/2018/05/23/cross_entropy_loss/\n",
    "[https://github.com/mkocabas/focal-loss-keras]\n",
    "[https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
