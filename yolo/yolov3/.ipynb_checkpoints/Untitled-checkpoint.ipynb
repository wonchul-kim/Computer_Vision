{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f855ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfdb3093",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = parse_model_cfg('./cfgs/yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "523a2b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'net',\n",
       "  'batch': '64',\n",
       "  'subdivisions': '16',\n",
       "  'width': '608',\n",
       "  'height': '608',\n",
       "  'channels': '3',\n",
       "  'momentum': '0.9',\n",
       "  'decay': '0.0005',\n",
       "  'angle': '0',\n",
       "  'saturation': '1.5',\n",
       "  'exposure': '1.5',\n",
       "  'hue': '.1',\n",
       "  'learning_rate': '0.001',\n",
       "  'burn_in': '1000',\n",
       "  'max_batches': '500200',\n",
       "  'policy': 'steps',\n",
       "  'steps': '400000,450000',\n",
       "  'scales': '.1,.1'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '32',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '32',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'shortcut', 'from': '-3', 'activation': 'linear'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '1024',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '1024',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '1024',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '255',\n",
       "  'activation': 'linear'},\n",
       " {'type': 'yolo',\n",
       "  'mask': '6,7,8',\n",
       "  'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '80',\n",
       "  'num': '9',\n",
       "  'jitter': '.3',\n",
       "  'ignore_thresh': '.7',\n",
       "  'truth_thresh': '1',\n",
       "  'random': '1'},\n",
       " {'type': 'route', 'layers': '-4'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'upsample', 'stride': '2'},\n",
       " {'type': 'route', 'layers': '-1, 61'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '512',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '512',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '512',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '255',\n",
       "  'activation': 'linear'},\n",
       " {'type': 'yolo',\n",
       "  'mask': '3,4,5',\n",
       "  'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '80',\n",
       "  'num': '9',\n",
       "  'jitter': '.3',\n",
       "  'ignore_thresh': '.7',\n",
       "  'truth_thresh': '1',\n",
       "  'random': '1'},\n",
       " {'type': 'route', 'layers': '-4'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'upsample', 'stride': '2'},\n",
       " {'type': 'route', 'layers': '-1, 36'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '256',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '256',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'batch_normalize': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '256',\n",
       "  'activation': 'leaky'},\n",
       " {'type': 'convolutional',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'pad': '1',\n",
       "  'filters': '255',\n",
       "  'activation': 'linear'},\n",
       " {'type': 'yolo',\n",
       "  'mask': '0,1,2',\n",
       "  'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '80',\n",
       "  'num': '9',\n",
       "  'jitter': '.3',\n",
       "  'ignore_thresh': '.7',\n",
       "  'truth_thresh': '1',\n",
       "  'random': '1'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59ba3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modules(blocks):\n",
    "    '''\n",
    "        * return: block의 정보를 토대로 pytorch의 nn.Module에 재구성하여 \n",
    "                  nn.ModuleList로 반환\n",
    "    '''\n",
    "    net_info = blocks[0]\n",
    "    module_list = nn.ModuleList()\n",
    "    prev_filters = 3               # 초기의 이미지는 RGB \n",
    "    output_filters = []            # conv., route, shortcut layer를 사용하기 위해서는 \n",
    "                                   # 지속적인 channel의 수에 대한 추적이 필요\n",
    "        \n",
    "    for index, x in enumerate(blocks[1:]):\n",
    "        # 하나의 block에는 여러 layer가 포함되어 있고, 이를 연속적으로 실행하기 위한 nn.Sequential()\n",
    "        module = nn.Sequential()\n",
    "        \n",
    "        if x['type'] == 'convolutional':            \n",
    "            \n",
    "            activation = x['activation']\n",
    "            try:\n",
    "                batch_normalize = int(x['batch_normalize'])\n",
    "                bias = False\n",
    "            except:\n",
    "                batch_normalize = 0\n",
    "                bias = True\n",
    "            \n",
    "            filters = int(x['filters'])\n",
    "            padding = int(x['pad'])\n",
    "            kernel_size = int(x['size'])\n",
    "            stride = int(x['stride'])\n",
    "            \n",
    "            if padding:\n",
    "                pad = (kernel_size - 1) // 2\n",
    "            else:\n",
    "                pad = 0\n",
    "\n",
    "            conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias = bias)\n",
    "            module.add_module('conv_{0}'.format(index),conv)\n",
    "\n",
    "            \n",
    "            if batch_normalize:\n",
    "                bn = nn.BatchNorm2d(filters)\n",
    "                module.add_module('batch_norm_{0}'.format(index),bn)\n",
    "                \n",
    "            if activation == 'leaky':\n",
    "                activn = nn.LeakyReLU(0.1, inplace = True)\n",
    "                module.add_module('leaky_{0}'.format(index), activn)\n",
    "                \n",
    "        elif x['type'] == 'upsample':\n",
    "            stride = int(x['stride'])\n",
    "            upsample = nn.Upsample(scale_factor = 2, mode = 'bilinear')\n",
    "            module.add_module('upsample_{}'.format(index), upsample)\n",
    "    \n",
    "        elif x['type'] == 'route':\n",
    "            x['layers'] = x['layers'].split(',')\n",
    "            start = int(x['layers'][0])\n",
    "            try:\n",
    "                end = int(x['layers'][1])\n",
    "            except:\n",
    "                end = 0\n",
    "        \n",
    "            if start > 0:  # 양수라면 route layer에서 어느 만큼 앞의 layer인지\n",
    "                start = start - index\n",
    "            if end > 0:\n",
    "                end = end - index\n",
    "\n",
    "            route = EmptyLayer()\n",
    "            module.add_module('route_{0}'.format(index), route)\n",
    "\n",
    "            # 음수 인 경우\n",
    "            if end < 0:\n",
    "                filters = output_filters[index + start] + output_filters[index + end]\n",
    "            else:\n",
    "                filters = output_filters[index + start]\n",
    "\n",
    "        elif x['type'] == 'shortcut':\n",
    "            shortcut = EmptyLayer()\n",
    "            module.add_module('shortcut_{}'.format(index), shortcut)\n",
    "            \n",
    "        elif x['type'] == 'yolo':\n",
    "            mask = x['mask'].split(',')\n",
    "            mask = [int(x) for x in mask]\n",
    "\n",
    "            anchors = x['anchors'].split(',')\n",
    "            anchors = [int(a) for a in anchors]\n",
    "            anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors),2)]\n",
    "            anchors = [anchors[i] for i in mask]\n",
    "\n",
    "            detection = DetectionLayer(anchors)\n",
    "            module.add_module('Detection_{}'.format(index), detection)\n",
    "        \n",
    "        module_list.append(module)\n",
    "        prev_filters = filters\n",
    "        output_filters.append(filters)\n",
    "        \n",
    "        return (net_info, module_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4faaa8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmptyLayer, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37f17829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionLayer(nn.Module):\n",
    "    def __init__(self,anchors):\n",
    "        super(DetectionLayer, self).__init__()\n",
    "        \n",
    "        self.anchors = anchors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8707a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_modules(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7db5b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'type': 'net',\n",
       "  'batch': '64',\n",
       "  'subdivisions': '16',\n",
       "  'width': '608',\n",
       "  'height': '608',\n",
       "  'channels': '3',\n",
       "  'momentum': '0.9',\n",
       "  'decay': '0.0005',\n",
       "  'angle': '0',\n",
       "  'saturation': '1.5',\n",
       "  'exposure': '1.5',\n",
       "  'hue': '.1',\n",
       "  'learning_rate': '0.001',\n",
       "  'burn_in': '1000',\n",
       "  'max_batches': '500200',\n",
       "  'policy': 'steps',\n",
       "  'steps': '400000,450000',\n",
       "  'scales': '.1,.1'},\n",
       " ModuleList(\n",
       "   (0): Sequential(\n",
       "     (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (leaky_0): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e997be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
